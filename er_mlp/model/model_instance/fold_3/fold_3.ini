[DEFAULT]
# Word embedding will use the average of the consituent words contained in the entity to produce the entity embedding.
# If false, it will randomly initialize an embedding for each entity.
WORD_EMBEDDING = True

# Total number of epochs to train.
TRAINING_EPOCHS = 250

# Size of batch. Change appropriately.
BATCH_SIZE = 5100

# Number of iterations till logging is displayed.
DISPLAY_STEP = 5

# The embedding size for the entity or word.
EMBEDDING_SIZE = 50

# The number of features for an inner layer.
LAYER_SIZE = 60

# The learning rate for the optimizer.
LEARNING_RATE=0.001

# The number of corruptions to produce per positive sample.
CORRUPT_SIZE = 100

# The regularization parameter.
LAMBDA = 0.001

# 1 for adam, 0 for adagrad.
OPTIMIZER = 1

# 0 for tanh, 1 for sigmoid.
ACT_FUNCTION = 0

# Number of additional inner layers to add. The activation layer for each inner layer will be relu.
ADD_LAYERS=3

# The drop out percentage for each additional layer added.
DROP_OUT_PERCENT = 0.5

# Are we using max margin training. This is deprecated and we must use Max margin.
MAX_MARGIN_TRAINING = True

# This is deprecated, use_range is no longer included.
USE_RANGE=False

# This is deprecated, use_neg is no longer included.
USE_NEG=False

# The train file name.
TRAIN_FILE=train.txt

# Will we be saving the model to disk?
SAVE_MODEL=True

# F1 threshold used for optimal threshold. False will use accuracy.
F1_FOR_THRESHOLD=True

# Use smolt sampling on the development set if we are calibrating the models.
USE_SMOLT_SAMPLING=True

# Use log reg or isotonic regression for calibration.
LOG_REG_CALIBRATE=True

# The regular expression that separates words in the entities and predicates.
SEPARATOR='#SPACE#|#COMMA#|#SEMICOLON#|\W+'

# The margin used for margin based ranking loss.
MARGIN=0.2

# The path to the data directory.
DATA_PATH=/home/jyoun/Jason/Research/KBase/Hypothesis_Generator/data/kb/folds/fold_3/
